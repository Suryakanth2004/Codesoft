# -*- coding: utf-8 -*-
"""Customer Churn Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SspHzDJSNxWuVE_ShdxDnkierrzMewVj
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")

data = pd.read_csv("Churn_Modelling.csv")
data

data.head()

data.info()

data.isnull().sum()

data.columns

data = data.drop(['RowNumber', 'CustomerId', 'Surname'],axis=1)
data

data = pd.get_dummies(data,drop_first = True)
data.head()
data = data.astype(int)
data

data['Exited'].value_counts()

plt.figure(figsize =(8,6))
sns.countplot(x='Exited',data = data)

X = data.drop('Exited',axis=1)
y = data['Exited']

!pip install imblearn

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression , LogisticRegression
from sklearn.metrics import r2_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score, recall_score, f1_score

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)
print('Training Shape: ', X_train.shape)
print('Testing Shape: ', X_test.shape)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

X_train_scaled

"""***Logistic Regression***"""

threshold = 0.5
y_train_classified = [1 if value > threshold else 0 for value in y_train]
LogisticRegression = LogisticRegression()
LogisticRegression.fit(X_train_scaled, y_train_classified)

y_test_classified = [1 if value > threshold else 0 for value in y_test]
accuracy1 = LR.score(X_test_scaled, y_test_classified)
print("Model Accuracy:", accuracy1)

"""**Random Forest**"""

threshold = 0.5
y_train_classified = [1 if value > threshold else 0 for value in y_train]
RandomForest = RandomForestClassifier()
RandomForest.fit(X_train_scaled, y_train_classified)

y_test_classified = [1 if value > threshold else 0 for value in y_test]
accuracy2 = rf.score(X_test_scaled, y_test_classified)
print("Model Accuracy:", accuracy2)

"""**Gradient Boosting Classifier**"""

from sklearn.ensemble import GradientBoostingClassifier
threshold = 0.5
y_train_classified = [1 if value > threshold else 0 for value in y_train]
GradientBoostingClassifier = GradientBoostingClassifier()
GradientBoostingClassifier.fit(X_train_scaled, y_train_classified)

y_test_classified = [1 if value > threshold else 0 for value in y_test]
accuracy3 = GBC.score(X_test_scaled, y_test_classified)
print("Model Accuracy:", accuracy3)

performance_summary = pd.DataFrame({
    'MODEL':['LogisticRegression','RandomForest','GradientBoostingClassifier'],
    'ACCURACY':[accuracy1,
           accuracy2,
           accuracy3,
          ]
})
performance_summary

from matplotlib import pyplot as plt
performance_summary['ACCURACY'].plot(kind='line', figsize=(8, 4), title='ACCURACY')
plt.gca().spines[['top', 'right']].set_visible(False)